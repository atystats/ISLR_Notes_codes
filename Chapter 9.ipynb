{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 9 \n",
    "# Support Vector Machines\n",
    "\n",
    "SVM is a generalization of a simple and intuitive classifier called the _Maximal margin classifier_.\n",
    "\n",
    "## Maximal Margin Classifier\n",
    "__Hyperplane__ :- In a p-dimensional space, a flat affice subspace of dimension p-1. In 2 dimensional space, a hyperplane is a line. \n",
    "\n",
    "In 2-dimension space, a hyperplane is defined as $$\\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 = 0$$ for paramters $\\beta_0, \\beta_1 and \\beta_2$.\n",
    "\n",
    "Any $X = (X_1, X_2)^T$ for which above equation holds is a point on the hyperplane. In 2 dimension, a hyperplane is a line.\n",
    "\n",
    "In case of p-dimension, a hyperplane $\\beta_0 + \\beta_1 X_1 +.....+ \\beta_p X_p = 0$ defines a p-dimensional hyperplane.\n",
    "\n",
    "Now, suppose that X does not satisfy the above equation. If $\\beta_0 + \\beta_1 X_1 +.....+ \\beta_p X_p > 0$, then X lies to one side of the hyperplane and if $\\beta_0 + \\beta_1 X_1 +.....+ \\beta_p X_p < 0$, then X lies on the other side of the hyperplane. \n",
    "\n",
    "So, a hyperplane is dividing p-dimensional space into 2 halves.\n",
    "\n",
    "### Classification using a seperating Hyperplane:-\n",
    "For a n X p data matrix X where all observations fall into two classes, $y_1,....,y_n\\  \\epsilon $ {-1,1} and a set of test observations $x^* = (x_1^*,....,x_p^*)$.\n",
    "\n",
    "Goal is to develop a classifier based on training data that will correctly classify the test observation using its feature measurement.\n",
    "\n",
    "__Seperating hyperplane__ :- Suppose it's possible to construct a hyperplane that seperates the training observations perfectly according to their class labels. Then a seperating hyperplane has the property that \n",
    "$$y_i(\\beta_0 + \\beta_1 X_{i1} +.....+ \\beta_p X_{ip}) > 0$$ for all i = 1,2,...,n.\n",
    "\n",
    "For test observation classification, we can look at sign of $f(x^*) = \\beta_0 + \\beta_1 X_1^* +.....+ \\beta_p X_p^*$.\n",
    "* If $f(x^*)$ is negetive, then class = -1.\n",
    "* If $f(x^*)$ is positive, then class = 1.\n",
    "\n",
    "We can use magnitude of $f(x^*)$. If $f(x^*)$ far from zero, $x^*$ lies far from hyperplane and we are more confident about our classification and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
